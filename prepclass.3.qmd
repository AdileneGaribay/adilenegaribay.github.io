---
title: "Prepare for Class #3"
editor: visual
---

##  1. Assigned Reading

-   [ ] a. Walker, Kyle. 2023.

### 2. Get Census API Key

-   [ ] Completed

### 3. Weekly Challenge 

-   Getting familiar with data import in R:

    -   What are the most commonly used packages for importing data in R?

    **readr**: part of the tidyverse and best for CSV, TSV, and delimited text files. **data.table**: primarily a data manipulation package with a notable feature fread() function, which is fast for reading large delimited files. **readxl**: best for excel files. **haven**: ideal for importing clinical trial or survey data from legacy systems. **foreign**: less modern than haven, but still widely used. **openxl**:great for exporting formatted spreadsheets without Java dependencies. **jsonlite**: useful for APIs and nested data structures. **DBI+odbc**:connects R to relational databases using ODBC drivers. **RSQLite**:lightweight and great for prototyping.

    -   *Conventional formats*

        -   **Commas-separated values (CSV)**

            -   a plain text file that stores tabular data, with each line representing a row of data and each value within a row separated by a comma

        -   **SPSS**

            -   a widely used statistical analysis software for collecting, editing, and analyzing data, especially in the social sciences

        -   **Stata**

            -   an integrated statistical software package used for data management, analysis, and graphics by researchers in fields like economics, biomedicine, and social sciences

        -   **XML**

            -   a plain-text, human-readable format used for storing and transporting data, allowing computers and applications to exchange information in a universally understood way

        -   **JSON**

            -   a lightweight, text-based format for storing and exchanging data that is both human-readable and easily understood by machines

    -   *New Formats*

        -   **Feather**

            -   a fast, lightweight, and language-agnostic binary file format for storing data frames. It is designed for efficient, low-overhead data transfer between data analysis languages like Python and R. 

        -   **Parquet**

            -   an open-source, column-oriented data file format designed for efficient data storage and retrieval, particularly in big data applications. 

        -   **Arrow IPC**

            -   a standardized protocol for efficiently transferring [columnar data](https://www.google.com/search?sca_esv=cdd4458fa27f824d&cs=1&q=columnar+data&sa=X&ved=2ahUKEwilubGbjNyPAxV3JNAFHdhpNrYQxccNegQIAxAC&mstk=AUtExfDjksKERN7jcCwTQBH1qxBI5_LtWsjFHM0f2EFZlilpVn_2EgX_6Cf_SidctY33bQ4354NHHfaO64nCItD60t4k1WPEEcAewSxY40Hc7kkKjGdugtN9KikfKFlP9gnpBEM&csui=3) between processes or systems without needing serialization or deserialization, as it uses the Arrow in-memory format directly

        -   **ORC**

            -   data stored in the Optimized Row Columnar (ORC) file format, an open-source, columnar file format designed for big data processing in the Apache Hadoop ecosystem

        -   **HDF**

            -   ([Hierarchical Data Format](https://www.google.com/search?sca_esv=cdd4458fa27f824d&cs=1&q=Hierarchical+Data+Format&sa=X&ved=2ahUKEwjy0-G2jNyPAxVRJNAFHbRoF-gQxccNegQIBBAB&mstk=AUtExfCrYKlsWHlL8hqLmbhYqiTemisTv2hqhGi2VmSFlRaK7PV87N1gTkukk9xImwE3iBDJXnWvj0CglguOjWujl5dSg2xrFXuw8JqR3GdEbwUM1SIbBKfXUAI-lRAJeoyZXrE&csui=3)) is a set of self-describing, platform-independent file formats for storing and managing scientific, engineering, and remote sensing data

        -   **Zarr**

            -   an open standard for storing large multidimensional array data.

        -   **Avro**

            -   a language-neutral data serialization system. It provides a compact, fast, binary data format for storing and exchanging data, along with a rich data structure definition system.
