[
  {
    "objectID": "prpclss4.html#read",
    "href": "prpclss4.html#read",
    "title": "Prepare For Class 4",
    "section": "2.Read",
    "text": "2.Read\n\nFoster ch.2 (Scraping sections 2.2)\nR4Ds(2e) ch.Â 24\nAdditional/Optional:Aydin,Olgun. 2018. R Web Scraping Quick Start Guide"
  },
  {
    "objectID": "prpclss4.html#research",
    "href": "prpclss4.html#research",
    "title": "Prepare For Class 4",
    "section": "3. Research",
    "text": "3. Research\n\nR packages for web scraping\nChoose two for comparison\nWhat is robots.txt?\nFind two websitesâ€™ robots.txt and analyze"
  },
  {
    "objectID": "prepclass.3.html",
    "href": "prepclass.3.html",
    "title": "Prepare for Class 3",
    "section": "",
    "text": "a. Walker, Kyle. 2023.\n\n\n\n\nCompleted\n\n\n\n\n\nGetting familiar with data import in R:\n\nWhat are the most commonly used packages for importing data in R?\n\nreadr: part of the tidyverse and best for CSV, TSV, and delimited text files. data.table: primarily a data manipulation package with a notable feature fread() function, which is fast for reading large delimited files. readxl: best for excel files. haven: ideal for importing clinical trial or survey data from legacy systems. foreign: less modern than haven, but still widely used. openxl:great for exporting formatted spreadsheets without Java dependencies. jsonlite: useful for APIs and nested data structures. DBI+odbc:connects R to relational databases using ODBC drivers. RSQLite:lightweight and great for prototyping.\n\nConventional formats\n\nCommas-separated values (CSV)\n\na plain text file that stores tabular data, with each line representing a row of data and each value within a row separated by a comma\n\nSPSS\n\na widely used statistical analysis software for collecting, editing, and analyzing data, especially in the social sciences\n\nStata\n\nan integrated statistical software package used for data management, analysis, and graphics by researchers in fields like economics, biomedicine, and social sciences\n\nXML\n\na plain-text, human-readable format used for storing and transporting data, allowing computers and applications to exchange information in a universally understood way\n\nJSON\n\na lightweight, text-based format for storing and exchanging data that is both human-readable and easily understood by machines\n\n\nNew Formats\n\nFeather\n\na fast, lightweight, and language-agnostic binary file format for storing data frames. It is designed for efficient, low-overhead data transfer between data analysis languages like Python and R.Â \n\nParquet\n\nan open-source, column-oriented data file format designed for efficient data storage and retrieval, particularly in big data applications.Â \n\nArrow IPC\n\na standardized protocol for efficiently transferringÂ columnar dataÂ between processes or systems without needing serialization or deserialization, as it uses the Arrow in-memory format directly\n\nORC\n\ndata stored in the Optimized Row Columnar (ORC) file format, an open-source, columnar file format designed for big data processing in the Apache Hadoop ecosystem\n\nHDF\n\n(Hierarchical Data Format)Â isÂ a set of self-describing, platform-independent file formats for storing and managing scientific, engineering, and remote sensing data\n\nZarr\n\nan open standard for storing large multidimensional array data.\n\nAvro\n\na language-neutral data serialization system.Â It provides a compact, fast, binary data format for storing and exchanging data, along with a rich data structure definition system."
  },
  {
    "objectID": "prepclass.3.html#assigned-reading",
    "href": "prepclass.3.html#assigned-reading",
    "title": "Prepare for Class 3",
    "section": "",
    "text": "a. Walker, Kyle. 2023.\n\n\n\n\nCompleted\n\n\n\n\n\nGetting familiar with data import in R:\n\nWhat are the most commonly used packages for importing data in R?\n\nreadr: part of the tidyverse and best for CSV, TSV, and delimited text files. data.table: primarily a data manipulation package with a notable feature fread() function, which is fast for reading large delimited files. readxl: best for excel files. haven: ideal for importing clinical trial or survey data from legacy systems. foreign: less modern than haven, but still widely used. openxl:great for exporting formatted spreadsheets without Java dependencies. jsonlite: useful for APIs and nested data structures. DBI+odbc:connects R to relational databases using ODBC drivers. RSQLite:lightweight and great for prototyping.\n\nConventional formats\n\nCommas-separated values (CSV)\n\na plain text file that stores tabular data, with each line representing a row of data and each value within a row separated by a comma\n\nSPSS\n\na widely used statistical analysis software for collecting, editing, and analyzing data, especially in the social sciences\n\nStata\n\nan integrated statistical software package used for data management, analysis, and graphics by researchers in fields like economics, biomedicine, and social sciences\n\nXML\n\na plain-text, human-readable format used for storing and transporting data, allowing computers and applications to exchange information in a universally understood way\n\nJSON\n\na lightweight, text-based format for storing and exchanging data that is both human-readable and easily understood by machines\n\n\nNew Formats\n\nFeather\n\na fast, lightweight, and language-agnostic binary file format for storing data frames. It is designed for efficient, low-overhead data transfer between data analysis languages like Python and R.Â \n\nParquet\n\nan open-source, column-oriented data file format designed for efficient data storage and retrieval, particularly in big data applications.Â \n\nArrow IPC\n\na standardized protocol for efficiently transferringÂ columnar dataÂ between processes or systems without needing serialization or deserialization, as it uses the Arrow in-memory format directly\n\nORC\n\ndata stored in the Optimized Row Columnar (ORC) file format, an open-source, columnar file format designed for big data processing in the Apache Hadoop ecosystem\n\nHDF\n\n(Hierarchical Data Format)Â isÂ a set of self-describing, platform-independent file formats for storing and managing scientific, engineering, and remote sensing data\n\nZarr\n\nan open standard for storing large multidimensional array data.\n\nAvro\n\na language-neutral data serialization system.Â It provides a compact, fast, binary data format for storing and exchanging data, along with a rich data structure definition system."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Clinical Research Coordinator | Aspiring Data Scientist\nğŸ“ Dallas, TXâ€ƒ|â€ƒğŸ“§ adilenegaribay2@gmail.comâ€ƒ\n\n\n\nA self-motivated and resilient student with a diverse set of skills and interests in statistical analysis, legal analysis, and research. Developed in communication, leadership, and analytical thinking. Seeking internship opportunities in Public Policy analysis and research.\n\n\n\n\nStudies in Criminal Justice (CJUS 4860) â€” Aug 2023\nAdvanced quantitative analysis applied to social science research using SPSS, in collaboration with Dr.Â Bartula.\nLegal Research and Writing (BLAW 4360) â€” Janâ€“May 2023\nAnalyzed legal documents, practiced citation formats, and applied the IRAC method.\nCriminal Justice Statistics (CJUS 3350) â€” Janâ€“May 2023\nDeveloped SPSS proficiency for analyzing social data.\nPolitical Science Quantitative Research (PSCI 4350) â€” Augâ€“Dec 2022\nLearned statistical formulas and STATA software fundamentals.\nResearch Methods (PSCI 2307) â€” Janâ€“May 2022\nGained proficiency in research design across social sciences.\n\n\n\n\nDallas VA Medical Center\nClinical Research Coordinator â€“ Nuclear Medicine\nJune 2023 â€“ Present\n- Coordinate clinical trials in nuclear medicine with strict regulatory compliance\n- Manage patient data, consent forms, and IRB documentation\n- Collaborate with physicians and research staff to ensure protocol adherence\n- Support data collection and reporting for FDA and VA research standards\nUNT Dallas Learning Commons\nWriting and Criminal Justice Statistics Tutor\nAug 2023 â€“ Present\n- Improved student writing through grammar and structure coaching\n- Guided students in SPSS and R for statistical analysis\n- Provided personalized tutoring and feedback for academic success\n- Supported research projects with data cleaning and interpretation\n\n\n\n\nHuman Capital Theory & Hispanic Educational Attainment â€” Feb 2023\n- Conducted literature review and database research\n- Cleaned and analyzed data using SPSS\n- Presented findings on public policy implications for Hispanic students in higher education\n\n\n\n\nSPSS:\n- Data cleaning, T-tests, multiple/logistic regression, partial correlation, multivariate analysis\nWriting:\n- APA 7, peer-reviewed article critique, legal analysis\nCommunication:\n- Emotional intelligence, public speaking, presentation design\nOther:\n- Research, organization, critical thinking, collaboration, adaptability\n\n\n\n\nPre-Law Society Secretary â€” UT Dallas, Apr 2023\n- Hosted workshops on law school applications, writing, and resume-building\n- Coordinated speaker events with attorneys and law students\nMcNair Scholar â€” UNT Dallas, Dec 2022\n- Developed public presentation, academic resilience, and research skills\n\n\n\n\nMcNair Scholar Peer Mentorship â€” Jul 2023\n- Guided new scholars in research development and program navigation\nPre-Law Society Peer Guidance â€” May 2023\n- Fostered collaborative support for students pursuing postgraduate programs\n\n\n\n\nAaron Bartula\nFaculty Research Mentor & Professor\nğŸ“§ Aaron.Bartula@untdallas.edu\nCurtis McDowell\nMcNair Research Director & Professor\nğŸ“§ Curtis.McDowell@untdallas.edu"
  },
  {
    "objectID": "cv.html#profile",
    "href": "cv.html#profile",
    "title": "CV",
    "section": "",
    "text": "A self-motivated and resilient student with a diverse set of skills and interests in statistical analysis, legal analysis, and research. Developed in communication, leadership, and analytical thinking. Seeking internship opportunities in Public Policy analysis and research."
  },
  {
    "objectID": "cv.html#coursework",
    "href": "cv.html#coursework",
    "title": "CV",
    "section": "",
    "text": "Studies in Criminal Justice (CJUS 4860) â€” Aug 2023\nAdvanced quantitative analysis applied to social science research using SPSS, in collaboration with Dr.Â Bartula.\nLegal Research and Writing (BLAW 4360) â€” Janâ€“May 2023\nAnalyzed legal documents, practiced citation formats, and applied the IRAC method.\nCriminal Justice Statistics (CJUS 3350) â€” Janâ€“May 2023\nDeveloped SPSS proficiency for analyzing social data.\nPolitical Science Quantitative Research (PSCI 4350) â€” Augâ€“Dec 2022\nLearned statistical formulas and STATA software fundamentals.\nResearch Methods (PSCI 2307) â€” Janâ€“May 2022\nGained proficiency in research design across social sciences."
  },
  {
    "objectID": "cv.html#experience",
    "href": "cv.html#experience",
    "title": "CV",
    "section": "",
    "text": "Dallas VA Medical Center\nClinical Research Coordinator â€“ Nuclear Medicine\nJune 2023 â€“ Present\n- Coordinate clinical trials in nuclear medicine with strict regulatory compliance\n- Manage patient data, consent forms, and IRB documentation\n- Collaborate with physicians and research staff to ensure protocol adherence\n- Support data collection and reporting for FDA and VA research standards\nUNT Dallas Learning Commons\nWriting and Criminal Justice Statistics Tutor\nAug 2023 â€“ Present\n- Improved student writing through grammar and structure coaching\n- Guided students in SPSS and R for statistical analysis\n- Provided personalized tutoring and feedback for academic success\n- Supported research projects with data cleaning and interpretation"
  },
  {
    "objectID": "cv.html#projects",
    "href": "cv.html#projects",
    "title": "CV",
    "section": "",
    "text": "Human Capital Theory & Hispanic Educational Attainment â€” Feb 2023\n- Conducted literature review and database research\n- Cleaned and analyzed data using SPSS\n- Presented findings on public policy implications for Hispanic students in higher education"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "CV",
    "section": "",
    "text": "SPSS:\n- Data cleaning, T-tests, multiple/logistic regression, partial correlation, multivariate analysis\nWriting:\n- APA 7, peer-reviewed article critique, legal analysis\nCommunication:\n- Emotional intelligence, public speaking, presentation design\nOther:\n- Research, organization, critical thinking, collaboration, adaptability"
  },
  {
    "objectID": "cv.html#memberships-affiliations",
    "href": "cv.html#memberships-affiliations",
    "title": "CV",
    "section": "",
    "text": "Pre-Law Society Secretary â€” UT Dallas, Apr 2023\n- Hosted workshops on law school applications, writing, and resume-building\n- Coordinated speaker events with attorneys and law students\nMcNair Scholar â€” UNT Dallas, Dec 2022\n- Developed public presentation, academic resilience, and research skills"
  },
  {
    "objectID": "cv.html#leadership-experience",
    "href": "cv.html#leadership-experience",
    "title": "CV",
    "section": "",
    "text": "McNair Scholar Peer Mentorship â€” Jul 2023\n- Guided new scholars in research development and program navigation\nPre-Law Society Peer Guidance â€” May 2023\n- Fostered collaborative support for students pursuing postgraduate programs"
  },
  {
    "objectID": "cv.html#references",
    "href": "cv.html#references",
    "title": "CV",
    "section": "",
    "text": "Aaron Bartula\nFaculty Research Mentor & Professor\nğŸ“§ Aaron.Bartula@untdallas.edu\nCurtis McDowell\nMcNair Research Director & Professor\nğŸ“§ Curtis.McDowell@untdallas.edu"
  },
  {
    "objectID": "assgn3op.html",
    "href": "assgn3op.html",
    "title": "Assignment 3 Output",
    "section": "",
    "text": "install.packages(â€œtidycensusâ€) library(tidycensus) census_api_key(â€œfc2cacf0853a53a209ebf8f1a57f2cd8d1994d3aâ€, install = FALSE) install.packages(â€œsfâ€) install.packages(â€œdplyrâ€) install.packages(â€œggplot2â€) library(ggplot2) install.packages(â€œreadrâ€) Sys.getenv(â€œCENSUS_API_KEYâ€)\nwi_income &lt;- get_acs( geography = â€œtractâ€, variables = c(medinc = â€œB19013_001â€, medage = â€œB17001_002â€), state = â€œWIâ€, county = â€œDaneâ€, year = 2020, geometry = TRUE)\nggplot(data = wi_income) + geom_sf(aes(fill = estimate), color = NA) + scale_fill_viridis_c( option = â€œplasmaâ€, name = â€œMedian Income ($)â€, na.value = â€œgrey80â€ ) + labs( title = â€œğŸ—ºï¸ Median Household Income by Census Tract in Dane County, WI (2020)â€, subtitle = â€œSource: U.S. Census Bureau, ACS 5-Year Estimatesâ€, caption = â€œNote: Tracts with missing data shown in grayâ€ ) + theme_minimal() + theme( plot.title = element_text(size = 16, face = â€œboldâ€), legend.title = element_text(size = 12), legend.text = element_text(size = 10) )"
  },
  {
    "objectID": "assgn1dv.html",
    "href": "assgn1dv.html",
    "title": "Assignment #1",
    "section": "",
    "text": "File: ansecombe01.R (available on Teams)\nRead: Anscombe, Francis J. (1973) â€” â€œGraphs in Statistical Analysisâ€\nWrite one paragraph analyzing the examples and suggesting improvements\n\n\n\n\n\n\nFile: Fall.R (available on Teams)\nApply your own custom color scheme\nExport the visualization and publish it on your GitHub site\n\n\n\n\n\n\nSelect a chart from a published source (book, article, or news website)\nWrite a critique discussing its effectiveness, clarity, and design choices"
  },
  {
    "objectID": "assgn1dv.html#data-visualization-assignment",
    "href": "assgn1dv.html#data-visualization-assignment",
    "title": "Assignment #1",
    "section": "",
    "text": "File: ansecombe01.R (available on Teams)\nRead: Anscombe, Francis J. (1973) â€” â€œGraphs in Statistical Analysisâ€\nWrite one paragraph analyzing the examples and suggesting improvements\n\n\n\n\n\n\nFile: Fall.R (available on Teams)\nApply your own custom color scheme\nExport the visualization and publish it on your GitHub site\n\n\n\n\n\n\nSelect a chart from a published source (book, article, or news website)\nWrite a critique discussing its effectiveness, clarity, and design choices"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assgn.2.html",
    "href": "assgn.2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Google Trends Data\n\na. Use google Trends Website to:\n\nSearch Trump, Kamala Harris and Election\nDownload Data\n\nAnalyze the data\n\nDates\n\nTrump: looking at the dates from 7/1/2024-12/1/2024, there is a peak on 7/14/2024. Following that peak, there is a steep drop until it rises again on 7/19/2024. It remains pretty stagnant at below 25, then peaks twice on 9/11 & 9/15. The term then remains stagnant until late October, where a steady rise peaks on 11/7/2024. There is then a significant drop off the following month.\nKamala: For the term Kamala, there is a peak at below 50 on 7/21/2024, with a drop and several peaks that remain at or below 25 until reaching a peak on 9/11/2024. The term remains stagnant until October and sees a gradual rise until it reaches a peak on 11/7/2024. There is a significant drop and it remains below 25 the following month.\nElection: The terms â€œElectionâ€ remains below 25, and gradually begins to rise in the end of October and reaches a peak on 11/7/2024. It then sees a significant drop and remains below 25 the following month.\n\nIntervals\n\n\n\nb. Use gtrendsR package to collect data (use gtrendsR01.R)\n\n\n\nc.Â Save the data into csv and R formats.\nd.Â What are the differences between the two methods?\n\nR allows the application of several layers, which makes the graphic easily digestible. It allows for the implementation of labels and differentiation of the different terms. Whereas CSV files provide only the numerical values of the objects."
  },
  {
    "objectID": "assgn3.html",
    "href": "assgn3.html",
    "title": "Assignment 3 Instructions",
    "section": "",
    "text": "Here is a map showing median household income by tract in Texas:\n njj ##Poverty Table: Top and Bototm 10 Tracts\n\n## ğŸ“‹ Poverty Table: Top and Bottom 10 Tracts\n\nlibrary(readr)\nlibrary(knitr)\n\npoverty_table &lt;- read_csv(\"data/poverty_table.csv\")\n\nRows: 20 Columns: 3\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): NAME\ndbl (2): estimate, moe\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nkable(poverty_table, caption = \"Top and Bottom 10 Tracts by Poverty Estimate\")\n\n\nTop and Bottom 10 Tracts by Poverty Estimate\n\n\nNAME\nestimate\nmoe\n\n\n\n\nCensus Tract 235.23; Hidalgo County; Texas\n4938\n2476\n\n\nCensus Tract 235.29; Hidalgo County; Texas\n4401\n1239\n\n\nCensus Tract 5429.02; Harris County; Texas\n4344\n2731\n\n\nCensus Tract 93.04; Dallas County; Texas\n4112\n1714\n\n\nCensus Tract 221.11; Hidalgo County; Texas\n4080\n1185\n\n\nCensus Tract 18.06; Webb County; Texas\n3998\n1286\n\n\nCensus Tract 123.02; Dallas County; Texas\n3877\n1152\n\n\nCensus Tract 13.03; Brazos County; Texas\n3860\n847\n\n\nCensus Tract 7003.02; Liberty County; Texas\n3653\n1695\n\n\nCensus Tract 120; Dallas County; Texas\n3514\n1507\n\n\nCensus Tract 9800; Nueces County; Texas\n0\n15\n\n\nCensus Tract 217.20; Denton County; Texas\n0\n15\n\n\nCensus Tract 9801; Cameron County; Texas\n0\n15\n\n\nCensus Tract 9803; Jefferson County; Texas\n0\n21\n\n\nCensus Tract 9802; Harris County; Texas\n0\n21\n\n\nCensus Tract 201.02; Jones County; Texas\n0\n21\n\n\nCensus Tract 305.12; Collin County; Texas\n0\n21\n\n\nCensus Tract 9800; Potter County; Texas\n0\n15\n\n\nCensus Tract 15; Tom Green County; Texas\n0\n15\n\n\nCensus Tract 9800; Harris County; Texas\n0\n15"
  },
  {
    "objectID": "assgn3.html#chloropleth-map-of-median-income",
    "href": "assgn3.html#chloropleth-map-of-median-income",
    "title": "Assignment 3 Instructions",
    "section": "",
    "text": "Here is a map showing median household income by tract in Texas:\n njj ##Poverty Table: Top and Bototm 10 Tracts\n\n## ğŸ“‹ Poverty Table: Top and Bottom 10 Tracts\n\nlibrary(readr)\nlibrary(knitr)\n\npoverty_table &lt;- read_csv(\"data/poverty_table.csv\")\n\nRows: 20 Columns: 3\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): NAME\ndbl (2): estimate, moe\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nkable(poverty_table, caption = \"Top and Bottom 10 Tracts by Poverty Estimate\")\n\n\nTop and Bottom 10 Tracts by Poverty Estimate\n\n\nNAME\nestimate\nmoe\n\n\n\n\nCensus Tract 235.23; Hidalgo County; Texas\n4938\n2476\n\n\nCensus Tract 235.29; Hidalgo County; Texas\n4401\n1239\n\n\nCensus Tract 5429.02; Harris County; Texas\n4344\n2731\n\n\nCensus Tract 93.04; Dallas County; Texas\n4112\n1714\n\n\nCensus Tract 221.11; Hidalgo County; Texas\n4080\n1185\n\n\nCensus Tract 18.06; Webb County; Texas\n3998\n1286\n\n\nCensus Tract 123.02; Dallas County; Texas\n3877\n1152\n\n\nCensus Tract 13.03; Brazos County; Texas\n3860\n847\n\n\nCensus Tract 7003.02; Liberty County; Texas\n3653\n1695\n\n\nCensus Tract 120; Dallas County; Texas\n3514\n1507\n\n\nCensus Tract 9800; Nueces County; Texas\n0\n15\n\n\nCensus Tract 217.20; Denton County; Texas\n0\n15\n\n\nCensus Tract 9801; Cameron County; Texas\n0\n15\n\n\nCensus Tract 9803; Jefferson County; Texas\n0\n21\n\n\nCensus Tract 9802; Harris County; Texas\n0\n21\n\n\nCensus Tract 201.02; Jones County; Texas\n0\n21\n\n\nCensus Tract 305.12; Collin County; Texas\n0\n21\n\n\nCensus Tract 9800; Potter County; Texas\n0\n15\n\n\nCensus Tract 15; Tom Green County; Texas\n0\n15\n\n\nCensus Tract 9800; Harris County; Texas\n0\n15"
  },
  {
    "objectID": "assign01.html",
    "href": "assign01.html",
    "title": "Assignment 1",
    "section": "",
    "text": "a. Read â€œCreating a Quarto Website and Deploying on GitHub Pagesâ€\nb. Install quarto in R i. In RStudio console, type: install.packages(â€œquartoâ€) and run ii. In RStudio terminal, type: quarto install, and enter.\nc. Create a New Project, choose New Directory and Quarto Website d.Â RStudio tutorial (with video): https://quarto.org/docs/get-started/hello/rstudio.html"
  },
  {
    "objectID": "assign01.html#setting-up",
    "href": "assign01.html#setting-up",
    "title": "Assignment 1",
    "section": "",
    "text": "a. Read â€œCreating a Quarto Website and Deploying on GitHub Pagesâ€\nb. Install quarto in R i. In RStudio console, type: install.packages(â€œquartoâ€) and run ii. In RStudio terminal, type: quarto install, and enter.\nc. Create a New Project, choose New Directory and Quarto Website d.Â RStudio tutorial (with video): https://quarto.org/docs/get-started/hello/rstudio.html"
  },
  {
    "objectID": "assign01.html#note",
    "href": "assign01.html#note",
    "title": "Assignment 1",
    "section": "2. Note",
    "text": "2. Note"
  },
  {
    "objectID": "assign01.html#include-your-updated-cvresume-on-your-navigation-bar.",
    "href": "assign01.html#include-your-updated-cvresume-on-your-navigation-bar.",
    "title": "Assignment 1",
    "section": "3. Include your updated CV/Resume on your navigation bar.",
    "text": "3. Include your updated CV/Resume on your navigation bar."
  },
  {
    "objectID": "assign01.html#write-a-one-page-not-on-designing-your-website",
    "href": "assign01.html#write-a-one-page-not-on-designing-your-website",
    "title": "Assignment 1",
    "section": "4. Write a one page not on designing your website:",
    "text": "4. Write a one page not on designing your website:\nSubmission: This Website is created using Rstudio Quarto. The theme is used for a professional look. The navigation bar includes CV, About, and Assignment links for connecting the authorâ€™s content in different areas."
  },
  {
    "objectID": "assign01.html#once-done-send-your-website-url-to-the-instructor",
    "href": "assign01.html#once-done-send-your-website-url-to-the-instructor",
    "title": "Assignment 1",
    "section": "5. Once done, send your website url to the instructor:",
    "text": "5. Once done, send your website url to the instructor:\na. Subject: Your name website\nb. The url should look like: karlho.github.io, johndoe11.github.io, in which karlho, johndoe11 are the username for GitHub login."
  },
  {
    "objectID": "prpclss3dv.html",
    "href": "prpclss3dv.html",
    "title": "Prepare for Class 3",
    "section": "",
    "text": "Ware, Colin. (2012)\n\n\n\n\n\nMcGhee, Geoff. (2011) â€” Journalism in the Age of Data\nIsabella Valesquez â€” Building with Quarto\n\n\n\n\n\nWrite a one-page review comparing journalistic vs.Â academic data visualization\nChoose RStudio method\nPublish to GitHub Pages"
  },
  {
    "objectID": "prpclss3dv.html#assignment-1",
    "href": "prpclss3dv.html#assignment-1",
    "title": "Prepare for Class 3",
    "section": "",
    "text": "Ware, Colin. (2012)\n\n\n\n\n\nMcGhee, Geoff. (2011) â€” Journalism in the Age of Data\nIsabella Valesquez â€” Building with Quarto\n\n\n\n\n\nWrite a one-page review comparing journalistic vs.Â academic data visualization\nChoose RStudio method\nPublish to GitHub Pages"
  },
  {
    "objectID": "Assignment2murrell.html",
    "href": "Assignment2murrell.html",
    "title": "Assignment 2",
    "section": "",
    "text": "### Paul Murrell's R examples (selected)\n\nplot(pressure, pch=16)  # Can you change pch?\n\n\n\n\n\n\n\n##pch changed to 25.\nplot(pressure,pch=25)\ntext(150, 600, \n     \"Pressure (mm Hg)\\nversus\\nTemperature (Celsius)\")\n\n\n\n\n\n\n\npar(mfrow=c(3, 2))\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=2) # Try different cex value?  \npoints(x, y2, pch=21, bg=\"white\", cex=2)  # Different background color\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for?\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\nY &lt;- rnorm(50)\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\nx &lt;- seq(-3.5, 3.5, .1)\ndn &lt;- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\n\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts &lt;- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx &lt;- seq(-10, 10, length= 30)\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\nz[is.na(z)] &lt;- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\n\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6))) \n\n\n\n\n\n\n\nknitr::include_graphics(\"/Users/adilenegaribay/Dropbox/Quarto/adilenegaribay.github.io/images/assignment2plots.png\")"
  }
]